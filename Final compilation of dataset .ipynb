{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max.columns', 100)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from calendar import monthrange \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import wikipedia\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000) \n",
    "pd.set_option ('display.max_columns' , 1000)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Data for comp/flight_delays_train.csv')\n",
    "y_train = train_data['dep_delayed_15min']\n",
    "x_test = pd.read_csv('Data for comp/flight_delays_test.csv')\n",
    "train_data['dep_delayed_15min'] = train_data['dep_delayed_15min'].map({'N':0, 'Y':1})\n",
    "x_train = train_data.drop(columns=['dep_delayed_15min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.concat([x_train, x_test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.index = np.arange(x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.insert(loc = 0, column = 'Initial Index', value = pd.Series(np.arange(0,200000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Air_Ports_Codes_Names = pd.read_excel('Data for comp/Airports .xlsx')\n",
    "Top_100_airports = pd.read_excel('Data for comp/Top Airports.xlsx')\n",
    "Climate_features = pd.read_excel('Data for comp/Climate features .xlsx')\n",
    "Air_line_codes = pd.read_excel('Data for comp/Airlines codes .xlsx')\n",
    "Top_By_passengers_carried = pd.read_excel('Data for comp/Top By passengers carried .xlsx')\n",
    "Top_By_fleet_size = pd.read_excel('Data for comp/Top By fleet size.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population_of_cities = pd.read_excel('Data for comp/Population .xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population_of_cities.drop(columns=['Unnamed: 0'],inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(887, 887)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(Population_of_cities['Geographic Area'])), Population_of_cities.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(810, 887):\n",
    "    Location = Population_of_cities.iloc[i, 0]\n",
    "    Population = find_num_population(Location)\n",
    "    Population_of_cities.iloc[i,1] = Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geographic Area</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Adak, Alaska</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Christiansted, U.S. Virgin Islands</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Cincinnati, Kentucky</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>Islip, New York</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>Key West, Florida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>Kinston, North Carolina</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Monterey, California</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>Newburgh, New York</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Sitka, Alaska</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Geographic Area  Population\n",
       "809                        Adak, Alaska         NaN\n",
       "817  Christiansted, U.S. Virgin Islands         NaN\n",
       "818                Cincinnati, Kentucky         NaN\n",
       "840                     Islip, New York         NaN\n",
       "847                   Key West, Florida         NaN\n",
       "849             Kinston, North Carolina         NaN\n",
       "862                Monterey, California         NaN\n",
       "868                  Newburgh, New York         NaN\n",
       "876                       Sitka, Alaska         NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Population_of_cities[Population_of_cities['Population'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numbers_ = [226,2626,301394,330914, 24843, 20398,28352,28866,8640]\n",
    "for i in Population_of_cities[Population_of_cities['Population'].isna()].index:\n",
    "    pos = 0\n",
    "    Population_of_cities.loc[i, 'Population'] = Numbers_[pos]\n",
    "    pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "States_Time_zones = pd.read_excel('Data for comp/Time Zones.xlsx')\n",
    "Time_zones = pd.read_excel('Data for comp/Differences between zones.xlsx')\n",
    "States_Time_zones['State'] = States_Time_zones['State'].apply(lambda x: x.split('(')[0])\n",
    "States_Time_zones['Time Zone'] = States_Time_zones['Time Zone'].apply(lambda x: x.split('(')[1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Codes = Air_line_codes['Passenger carrier:'].apply(lambda x: x.split(' ')[len(x.split(' ')) - 1])\n",
    "Codes = Codes.apply(lambda x: x[1:len(x) - 1])\n",
    "Air_lines = Air_line_codes['Passenger carrier:'].apply(lambda x: ' '.join(x.split(' ')[:len(x.split(' '))-1]))\n",
    "Air_line_codes = pd.DataFrame({'Air line': Air_lines, 'Code':Codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'N':0, 'Y':1}\n",
    "y_train = y_train.map(my_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(table):\n",
    "    for col in table.columns:\n",
    "        if table[col].dtype == 'int64' or table[col].dtype == 'float64':\n",
    "            table[col] = table[col].fillna(table[col].mean())\n",
    "    return table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_enc1(train_df, y_train, valid_df, skf):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    glob_mean = y_train.mean()\n",
    "    train_df = pd.concat([train_df, pd.Series(y_train, name='y')], axis=1)\n",
    "    new_train_df = train_df.copy()\n",
    "    \n",
    "    cat_features = train_df.columns[train_df.dtypes == 'object'].tolist()    \n",
    "\n",
    "    for col in cat_features:\n",
    "        new_train_df[col + '_mean_target'] = np.nan\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(train_df, y_train):\n",
    "        train_df_cv, valid_df_cv = train_df.iloc[train_idx, :], train_df.iloc[valid_idx, :]\n",
    "\n",
    "        for col in cat_features:\n",
    "            \n",
    "            means = valid_df_cv[col].map(train_df_cv.groupby(col)['y'].mean())\n",
    "            valid_df_cv[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "            \n",
    "        new_train_df.iloc[valid_idx] = valid_df_cv\n",
    "    \n",
    "    for col in cat_features:\n",
    "        means = valid_df[col].map(train_df.groupby(col)['y'].mean())\n",
    "        valid_df[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "    \n",
    "    return new_train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_enc_train(train_df, y_train, skf):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    glob_mean = y_train.mean()\n",
    "    train_df = pd.concat([train_df, pd.Series(y_train, name='y')], axis=1)\n",
    "    new_train_df = train_df.copy()\n",
    "    \n",
    "    cat_features = train_df.columns[train_df.dtypes == 'object'].tolist()    \n",
    "\n",
    "    for col in cat_features:\n",
    "        new_train_df[col + '_mean_target'] = np.nan\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(train_df, y_train):\n",
    "        train_df_cv, valid_df_cv = train_df.iloc[train_idx, :], train_df.iloc[valid_idx, :]\n",
    "\n",
    "        for col in cat_features:\n",
    "            \n",
    "            means = valid_df_cv[col].map(train_df_cv.groupby(col)['y'].mean())\n",
    "            valid_df_cv[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "            \n",
    "        new_train_df.iloc[valid_idx] = valid_df_cv\n",
    "    new_train_df.drop(cat_features + [\"y\"], axis=1, inplace=True)\n",
    "    return new_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Month_Seasons = {'1':'Winter',\n",
    "                 '2':'Winter',\n",
    "                 '3':'Spring', \n",
    "                 '4':'Spring', \n",
    "                 '5':'Spring', \n",
    "                 '6':'Summer', \n",
    "                 '7':'Summer', \n",
    "                 '8':'Summer', \n",
    "                 '9':'Fall', \n",
    "                 '10':'Fall', \n",
    "                 '11':'Fall', \n",
    "                 '12':'Winter'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_city(Pandas_Series):\n",
    "    Series_of_cities = Pandas_Series.apply(lambda x: x.split(',')).apply(lambda x: x[0])\n",
    "    Series_of_States  = Pandas_Series.apply(lambda x: x.split(',')).apply(lambda x: x[1])\n",
    "    list_of_cities = []\n",
    "    for city in Series_of_cities:\n",
    "        my_list = city.split(' ')\n",
    "        if 'city' in my_list:\n",
    "            my_list.remove('city')\n",
    "        if 'town'in my_list:\n",
    "            my_list.remove('town')\n",
    "        if 'village' in my_list:\n",
    "            my_list.remove('village')\n",
    "        if 'CDP' in my_list:\n",
    "            my_list.remove('CDP')\n",
    "        if 'urban' in my_list:\n",
    "            my_list.remove('urban')\n",
    "        if 'county' in my_list:\n",
    "            my_list.remove('county')\n",
    "        if '(Ventura)' in my_list:\n",
    "            my_list.remove('(Ventura)')\n",
    "        if 'municipality' in my_list:\n",
    "            my_list.remove('municipality')\n",
    "        if '(balance)' in my_list:\n",
    "            my_list.remove('(balance)')\n",
    "        if my_list[len(my_list)-1] == 'government':\n",
    "            my_list = my_list[0]\n",
    "        list_of_cities.append(my_list)\n",
    "    return pd.Series(list_of_cities).map(lambda x: ' '.join(x)) + Series_of_States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_duplicates(list_):\n",
    "    duplicates = []\n",
    "    set_list = set(list_)\n",
    "    dict_elements = {}\n",
    "    for elem in list_:\n",
    "        dict_elements[elem] = dict_elements.get(elem, 0) + 1\n",
    "        if dict_elements[elem] > 1:\n",
    "            duplicates.append(elem)\n",
    "    return list(set(duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_it_holyday (date): \n",
    "    if date in ['1-1', '1-18','5-31','7-5','9-6','11-11','11-25','12-24','12-31']:\n",
    "        return 'Holyday'\n",
    "    else:\n",
    "        return 'Not Holyday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_week_end (num_day):\n",
    "    num_day = str(num_day)\n",
    "    if num_day == '6' or num_day == '7':\n",
    "        return 'weekend'\n",
    "    else:\n",
    "        return ' not weekend'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_day (time):\n",
    "    if 400 < time <= 1200:\n",
    "        return 'Morning'\n",
    "    if 1200 < time <= 1700:\n",
    "        return 'Afternoon'\n",
    "    if 1700 < time <= 2100:\n",
    "        return 'Evening '\n",
    "    if 2100 < time or time <= 400:\n",
    "        return 'Night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_day1 (time):\n",
    "    if 0 < time <= 1200:\n",
    "        return 'Morning'\n",
    "    if 1200 < time <= 2400:\n",
    "        return 'Afternoon'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_of_month_ (date_data, num_parts = 4):\n",
    "    date_data = date_data.copy()\n",
    "    zero_series = pd.Series(np.zeros(date_data.shape[0]))\n",
    "    separated_data = date_data.apply(lambda x: x.split('-'))\n",
    "    for index_date in np.arange(date_data.shape[0]):\n",
    "        intervals = np.arange(1, num_parts+ 1) * (monthrange(2017,\n",
    "                                                            int(separated_data[index_date][0]))[1])/num_parts\n",
    "        for i in range(num_parts):\n",
    "            if int(separated_data[index_date][1]) <= intervals[i]:\n",
    "                zero_series[index_date] = i + 1\n",
    "                break\n",
    "    return zero_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_zones_shifts (data):\n",
    "    Time_zones = data.iloc[:,0].tolist()\n",
    "    Times = data.iloc[:,1].tolist()\n",
    "    dict_times_zones = dict()\n",
    "    dict_time_shifts = dict()\n",
    "    time_zone_combination = [*itertools.product(Time_zones, repeat=2)]\n",
    "    for i in range(len(Time_zones)):\n",
    "        dict_times_zones[Time_zones[i]] = dict_times_zones.get(Time_zones[i], Times[i])\n",
    "    for i in range(len(time_zone_combination)):\n",
    "        x_dest = time_zone_combination[i][0]\n",
    "        y_dest = time_zone_combination[i][1]\n",
    "        shift = dict_times_zones[y_dest] - dict_times_zones[x_dest]\n",
    "        dict_time_shifts[x_dest+'-'+y_dest] = dict_time_shifts.get(x_dest+'-'+y_dest, shift) \n",
    "    return dict_time_shifts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_hours_minutes (data):\n",
    "    def distinct_hours (time):\n",
    "        if len(str(time)) == 4:\n",
    "            return str(time)[:2]\n",
    "        elif len(str(time)) == 3:\n",
    "            return str(time)[0]\n",
    "        else:\n",
    "            return '0'\n",
    "    def distinct_minutes (time):\n",
    "        if len(str(time)) == 4:\n",
    "            return str(time)[2:4]\n",
    "        elif len(str(time)) == 3:\n",
    "            return str(time)[1:3]\n",
    "        else:\n",
    "            return str(time)\n",
    "    Series_of_hours = data.apply(distinct_hours)\n",
    "    Series_of_minutes = data.apply(distinct_minutes)\n",
    "    return Series_of_hours +'.'+Series_of_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_time(Time_series1, Time_series2):\n",
    "    Sum_minutes = Time_series1.apply(lambda x: int(x.split('.')[1])) + \\\n",
    "    Time_series2.apply(lambda x: int(x.split('.')[1]))\n",
    "    Sum_hours = Time_series1.apply(lambda x: int(x.split('.')[0])) + \\\n",
    "    Time_series2.apply(lambda x: int(x.split('.')[0]))\n",
    "    Residual_minutes = (Sum_minutes%60).apply(str)\n",
    "    Residual_hours = Sum_minutes//60\n",
    "    Sum_hours += Residual_hours\n",
    "    for i in Sum_hours.index:\n",
    "        if Sum_hours[i] >= 24:\n",
    "            Sum_hours[i] %=24\n",
    "    for i in Residual_minutes.index:\n",
    "        if int(Residual_minutes[i]) < 0:\n",
    "            Residual_minutes[i] = '0'+ Residual_minutes[i]\n",
    "    return Sum_hours.apply(str), Residual_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_to_time (number):\n",
    "    num_minutes = int(number * 60)\n",
    "    hours = num_minutes//60\n",
    "    minutes = num_minutes%60\n",
    "    if minutes < 10:\n",
    "         minutes = '0'+str(minutes)\n",
    "    return str(hours) + '.' + str(minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_hours (time):\n",
    "        if len(str(time)) == 4:\n",
    "            return int(str(time)[:2])\n",
    "        elif len(str(time)) == 3:\n",
    "            return int(str(time)[0])\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_minutes (time):\n",
    "        if len(str(time)) == 4:\n",
    "            return str(time)[2:4]\n",
    "        elif len(str(time)) == 3:\n",
    "            return str(time)[1:3]\n",
    "        else:\n",
    "            return str(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_colums_df (df):\n",
    "    Columns = df.columns.tolist()\n",
    "    Base_col = pd.Series(np.zeros(df.shape[0]))\n",
    "    for col in Columns:\n",
    "        Base_col += df[col]\n",
    "    return Base_col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_population(Name):\n",
    "    def extract_int(list):\n",
    "        list_int = []\n",
    "        for i in list:\n",
    "            try:\n",
    "                list_int.append(int(i))\n",
    "            except:\n",
    "                pass\n",
    "        return list_int\n",
    "    Name = Name.replace(', ', ',')\n",
    "    try:\n",
    "        import wikipedia\n",
    "        wikipedia_page = wikipedia.page(Name)\n",
    "        list_words = [*map(lambda x: x.lower(),wikipedia_page.summary.split(' '))]\n",
    "        loc = 0\n",
    "        for word in list_words:\n",
    "            if word == 'population':\n",
    "                break\n",
    "            else:\n",
    "                loc += 1\n",
    "        sub_list = list_words[loc: loc+20]\n",
    "        word_list = []\n",
    "        new_sub_list = []\n",
    "        for word_ in sub_list:\n",
    "            word_ = word_.replace('.\\n\\nthe', '').rstrip(',').rstrip(':').rstrip(';').rstrip('.')\n",
    "            new_sub_list.append(word_)\n",
    "            if ',' in word_:\n",
    "                word_list.append(word_)\n",
    "        if word_list != []:\n",
    "            number = word_list[0].split(',')\n",
    "            Population_region = int(number[0] + number[1])\n",
    "            return Population_region\n",
    "        else:\n",
    "            ints = extract_int(new_sub_list)\n",
    "            return ints[0]\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_geo_position (Location):\n",
    "    try:\n",
    "        page = wikipedia.page(Location)\n",
    "        coordinates = [*map(lambda x: float(round(x, 4)), page.coordinates)]\n",
    "        return coordinates\n",
    "    except:\n",
    "        try:\n",
    "            page = wikipedia.page(wikipedia.search(Location)[1])\n",
    "            coordinates = [*map(lambda x: float(round(x, 4)), page.coordinates)]\n",
    "            return coordinates\n",
    "\n",
    "        except:\n",
    "            return [np.NaN, np.NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_acres (Name):\n",
    "    def extract_int(list):\n",
    "        list_int = []\n",
    "        for i in list:\n",
    "            try:\n",
    "                if ',' in i:\n",
    "                    i_list = i.split(',')\n",
    "                    i = i_list[0] + i_list[1]\n",
    "                list_int.append(int(i))\n",
    "            except:\n",
    "                pass\n",
    "        return list_int\n",
    "    try:\n",
    "        wikipedia_page = wikipedia.page(Name)\n",
    "        list_words = [*map(lambda x: x.lower(),wikipedia_page.content.split(' '))]\n",
    "        pos_acres = []\n",
    "        loc = 0\n",
    "        for word in list_words:\n",
    "            word = word.replace('.\\n\\nthe', '').rstrip(',').rstrip(':').rstrip(';').rstrip('.')\n",
    "            if word == 'acres':\n",
    "                pos_acres.append(loc)\n",
    "            else:\n",
    "                loc += 1\n",
    "        if len(pos_acres) == 0:\n",
    "            return np.NaN\n",
    "        for position in pos_acres:\n",
    "            words_before_acre = list_words[position - 10:position + 1]\n",
    "            if 'covers' in words_before_acre:\n",
    "                all_ints = extract_int(words_before_acre)\n",
    "                if len(all_ints) == 1:\n",
    "                    num_arces = all_ints[0]\n",
    "                    break\n",
    "                else:\n",
    "                    num_arces = all_ints[-1]\n",
    "                    break\n",
    "        return num_arces\n",
    "    except:\n",
    "        return np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_esimation (data, num_samples, num_selections):\n",
    "    num_data_sumples = data.shape[0]\n",
    "    num_samples = int(num_data_sumples * num_samples)\n",
    "    dict_values = dict()\n",
    "    for key in set(data.values):\n",
    "        dict_values[key] = dict_values.get(key, [0] * num_selections)\n",
    "    for i in np.arange(num_selections):\n",
    "        index_selection = random.sample(range(0,num_data_sumples), num_samples)\n",
    "        sample = data[index_selection]\n",
    "        sample_values_share = sample.value_counts(normalize=True)\n",
    "        for value in sample_values_share.index:\n",
    "            dict_values[value][i] = sample_values_share[value]\n",
    "    data_value_shares = pd.DataFrame(dict_values).mean()\n",
    "    return data_value_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population_of_cities['Geographic Area'] = extract_name_city(Population_of_cities['Geographic Area'])\n",
    "Population_of_cities.rename(columns={'Geographic Area':'City'},inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Air_Ports_Codes_Names['City'] = Air_Ports_Codes_Names['City'] + ' ' + Air_Ports_Codes_Names['State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(887, 887)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(Population_of_cities['City'])), Population_of_cities.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = x_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = New_xtrain.merge(Air_Ports_Codes_Names, left_on= 'Origin', right_on= 'IATA')\n",
    "New_xtrain = New_xtrain.merge(Air_Ports_Codes_Names, left_on= 'Dest', right_on= 'IATA')\n",
    "New_xtrain.rename(columns={'City_x':'City'}, inplace = True)\n",
    "New_xtrain = New_xtrain.merge(Population_of_cities, on = 'City', how = 'left')\n",
    "New_xtrain.rename(columns={'City':'Origin_City', 'Population':'Origin_Population', 'City_y': 'City'}, inplace = True)\n",
    "New_xtrain = New_xtrain.merge(Population_of_cities, on = 'City', how = 'left')\n",
    "New_xtrain.rename(columns={'City':'Dest_City', 'Population':'Dest_Population'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_50_airports_list = Top_100_airports['Code'].tolist()\n",
    "Is_origin_airport_top = New_xtrain['Origin'].apply(lambda x: int(x in Top_50_airports_list))\n",
    "Is_dest_airport_top = New_xtrain['Dest'].apply(lambda x: int(x in Top_50_airports_list))\n",
    "df_air_port_top = pd.DataFrame({'Origin airport in top': Is_origin_airport_top,\n",
    "                               'Dest airport in top':Is_dest_airport_top})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_fleet_size = Top_By_fleet_size.merge(Air_line_codes, left_on='American Airlines', \n",
    "                                           right_on= 'Air line')['Code'].tolist()\n",
    "Top_passengers_carried = Top_By_passengers_carried.merge(Air_line_codes, left_on='Airline', \n",
    "                                           right_on= 'Air line')['Code'].tolist()\n",
    "DF_TOP_features = pd.DataFrame({'AL_in_Top_fleet_size': New_xtrain['UniqueCarrier'].apply(lambda x: int(x in Top_fleet_size)),\n",
    "                   'AL_in_Top_passengers_carried': New_xtrain['UniqueCarrier'].apply(lambda x: int(x in Top_passengers_carried))})\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Initial Index</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Airport_x</th>\n",
       "      <th>Origin_City</th>\n",
       "      <th>State_x</th>\n",
       "      <th>IATA_x</th>\n",
       "      <th>Airport_y</th>\n",
       "      <th>Dest_City</th>\n",
       "      <th>State_y</th>\n",
       "      <th>IATA_y</th>\n",
       "      <th>Origin_Population</th>\n",
       "      <th>Dest_Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>c-8</td>\n",
       "      <td>c-21</td>\n",
       "      <td>c-7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>Hartsfield–Jackson Atlanta International Airport</td>\n",
       "      <td>Atlanta Georgia</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Dallas/Fort Worth International Airport</td>\n",
       "      <td>Dallas Texas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>DFW</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>1342479.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Initial Index Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance                                         Airport_x      Origin_City  State_x IATA_x                                Airport_y     Dest_City State_y IATA_y  Origin_Population  Dest_Population\n",
       "0              0   c-8       c-21       c-7     1934            AA    ATL  DFW       732  Hartsfield–Jackson Atlanta International Airport  Atlanta Georgia  Georgia    ATL  Dallas/Fort Worth International Airport  Dallas Texas   Texas    DFW           491670.0        1342479.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_xtrain.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = pd.concat([New_xtrain ,DF_TOP_features, df_air_port_top], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain['Month'] = New_xtrain['Month'].apply(lambda x: x[2:])\n",
    "New_xtrain['DayofMonth'] = New_xtrain['DayofMonth'].apply(lambda x: x[2:])\n",
    "New_xtrain['DayOfWeek'] = New_xtrain['DayOfWeek'].apply(lambda x: x[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.sort_values(by = 'Initial Index', ascending= True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_data = New_xtrain[['Initial Index', 'Month','DayofMonth','DayOfWeek','DepTime','Distance','State_x','State_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_data1 = Time_data.merge(States_Time_zones, left_on= 'State_x', right_on= 'State')\n",
    "Time_data2 = Time_data1.merge(States_Time_zones, left_on= 'State_y', right_on= 'State')\n",
    "Time_data2.drop(columns = ['State_x', 'State_y'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_distances = time_zones_shifts(Time_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_data2['Shift Time'] = (Time_data2['Time Zone_x'] + '-' + Time_data2['Time Zone_y']).map(dict_distances)\n",
    "Time_data2.drop(columns=['Time Zone_x','Time Zone_y'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Initial Index</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Airport_x</th>\n",
       "      <th>Origin_City</th>\n",
       "      <th>State_x</th>\n",
       "      <th>IATA_x</th>\n",
       "      <th>Airport_y</th>\n",
       "      <th>Dest_City</th>\n",
       "      <th>State_y</th>\n",
       "      <th>IATA_y</th>\n",
       "      <th>Origin_Population</th>\n",
       "      <th>Dest_Population</th>\n",
       "      <th>AL_in_Top_fleet_size</th>\n",
       "      <th>AL_in_Top_passengers_carried</th>\n",
       "      <th>Origin airport in top</th>\n",
       "      <th>Dest airport in top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>1934</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>732</td>\n",
       "      <td>Hartsfield–Jackson Atlanta International Airport</td>\n",
       "      <td>Atlanta Georgia</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Dallas/Fort Worth International Airport</td>\n",
       "      <td>Dallas Texas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>DFW</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>1342479.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121276</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1548</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>834</td>\n",
       "      <td>Pittsburgh International Airport</td>\n",
       "      <td>Pittsburgh Pennsylvania</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PIT</td>\n",
       "      <td>Orlando International Airport</td>\n",
       "      <td>Orlando Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>MCO</td>\n",
       "      <td>301494.0</td>\n",
       "      <td>281804.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18325</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1422</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>416</td>\n",
       "      <td>Raleigh-Durham International Airport</td>\n",
       "      <td>Raleigh North Carolina</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>RDU</td>\n",
       "      <td>Cleveland-Hopkins International Airport</td>\n",
       "      <td>Cleveland Ohio</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>CLE</td>\n",
       "      <td>465776.0</td>\n",
       "      <td>385252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12703</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>1015</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>872</td>\n",
       "      <td>Denver International Airport</td>\n",
       "      <td>Denver Colorado</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Memphis International Airport</td>\n",
       "      <td>Memphis Tennessee</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>MEM</td>\n",
       "      <td>704961.0</td>\n",
       "      <td>650878.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Initial Index Month DayofMonth DayOfWeek  DepTime UniqueCarrier Origin Dest  Distance                                         Airport_x              Origin_City         State_x IATA_x                                Airport_y          Dest_City    State_y IATA_y  Origin_Population  Dest_Population  AL_in_Top_fleet_size  AL_in_Top_passengers_carried  Origin airport in top  Dest airport in top\n",
       "0                   0     8         21         7     1934            AA    ATL  DFW       732  Hartsfield–Jackson Atlanta International Airport          Atlanta Georgia         Georgia    ATL  Dallas/Fort Worth International Airport       Dallas Texas      Texas    DFW           491670.0        1342479.0                     0                             0                      1                    1\n",
       "121276              1     4         20         3     1548            US    PIT  MCO       834                  Pittsburgh International Airport  Pittsburgh Pennsylvania    Pennsylvania    PIT            Orlando International Airport    Orlando Florida    Florida    MCO           301494.0         281804.0                     0                             0                      1                    1\n",
       "18325               2     9          2         5     1422            XE    RDU  CLE       416              Raleigh-Durham International Airport   Raleigh North Carolina  North Carolina    RDU  Cleveland-Hopkins International Airport     Cleveland Ohio       Ohio    CLE           465776.0         385252.0                     0                             0                      1                    1\n",
       "12703               3    11         25         6     1015            OO    DEN  MEM       872                      Denver International Airport          Denver Colorado        Colorado    DEN            Memphis International Airport  Memphis Tennessee  Tennessee    MEM           704961.0         650878.0                     0                             0                      1                    0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_xtrain.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_time  = round((Time_data2['Distance']/561),2).apply(switch_to_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hours = sum_time(sep_hours_minutes(Time_data2['DepTime']),flight_time)[0]\n",
    "Minutes = sum_time(sep_hours_minutes(Time_data2['DepTime']),flight_time)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Minutes.index:\n",
    "    if int(Minutes[i]) < 10:\n",
    "        Minutes[i] = '0'+ Minutes[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_time = (Hours + Minutes).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_dest_time = (dest_time.apply(distinct_hours) + Time_data2['Shift Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(shifter_dest_time.shape[0]):\n",
    "     if shifter_dest_time[i] < 0:\n",
    "        shifter_dest_time[i] = 24 + shifter_dest_time[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Initial Index</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Shift Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>1934</td>\n",
       "      <td>732</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>255</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>925</td>\n",
       "      <td>874</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1418</td>\n",
       "      <td>874</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>442</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>1438</td>\n",
       "      <td>696</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>950</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>716</td>\n",
       "      <td>732</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>113881</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1338</td>\n",
       "      <td>865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>118563</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1801</td>\n",
       "      <td>865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>150559</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2028</td>\n",
       "      <td>865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>178501</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1338</td>\n",
       "      <td>865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>194121</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1742</td>\n",
       "      <td>865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Initial Index Month DayofMonth DayOfWeek  DepTime  Distance  Shift Time\n",
       "0                   0     8         21         7     1934       732          -1\n",
       "1                 255     4         12         3      925       874          -1\n",
       "2                 356    11          7         2     1418       874          -1\n",
       "3                 442     4         22         5     1438       696          -1\n",
       "4                 950    11         29         2      716       732          -1\n",
       "...               ...   ...        ...       ...      ...       ...         ...\n",
       "199995         113881     6         11         1     1338       865           1\n",
       "199996         118563     3         27         2     1801       865           1\n",
       "199997         150559     6          3         7     2028       865           1\n",
       "199998         178501     8         14         2     1338       865           1\n",
       "199999         194121     3          5         1     1742       865           1\n",
       "\n",
       "[200000 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_data2['Season'] = Time_data2['Month'].map(Month_Seasons)\n",
    "Time_data2['Is it holyday'] = (Time_data2['Month'] + '-'+  Time_data2['DayofMonth']).apply(is_it_holyday)\n",
    "Time_data2['Is it weekend'] = Time_data2['DayOfWeek'].apply(is_week_end)\n",
    "Time_data2['Part of month'] = part_of_month_(Time_data2['Month'] + '-' + Time_data2['DayofMonth'], 4)\n",
    "Time_data2['Land time'] = (shifter_dest_time.apply(str) + dest_time.apply(distinct_minutes)).apply(int)\n",
    "Time_data2['Land part of day'] = Time_data2['Land time'].apply(part_of_day)\n",
    "Time_data2['_2_part_of_day'] = Time_data2['DepTime'].apply(part_of_day1)\n",
    "Time_data2['_2_part_of_day_land'] = Time_data2['Land time'].apply(part_of_day1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Time_data2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_data2.insert(loc = 5, column= 'Dep part of day', value= Time_data2['DepTime'].apply(part_of_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time_data2.sort_values(by = 'Initial Index', ascending= True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.drop(columns=['Month','DayofMonth','DayOfWeek', 'Distance','DepTime'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = Time_data2.merge(New_xtrain, left_on= 'Initial Index', right_on= 'Initial Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in New_xtrain[New_xtrain['Land time'] > 2400].index:\n",
    "    Time = New_xtrain.loc[i, 'Land time']\n",
    "    if 2400 < Time < 4300:\n",
    "        Time_str = str(Time)\n",
    "        Minutes = Time_str[2:]\n",
    "        New_xtrain.loc[i, 'Land time'] = int(Minutes)\n",
    "    if Time >= 4300:\n",
    "        Time_str = str(Time)\n",
    "        Minutes = Time_str[2:]\n",
    "        New_xtrain.loc[i, 'Land time'] = int('23'+Minutes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "Climate_data = New_xtrain[['Initial Index',\n",
    "                           'Season',\n",
    "                           '_2_part_of_day',\n",
    "                           'State_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "Climate_data = Climate_data.rename(columns = {'State_x':'State'})\n",
    "Climate_data = (Climate_data.merge(Climate_features, on = 'State', how = 'left'))\n",
    "Climate_data = fill_nan(Climate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(Climate_data.shape[0]):\n",
    "    Season = Climate_data.loc[i,'Season']\n",
    "    for col in Climate_data.columns[4:]:\n",
    "        if Season not in col.split(' '):\n",
    "            Climate_data.loc[i, col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_f_temp = Climate_data.loc[:,'Spring - Avg ° C':'Winter - Avg ° C']\n",
    "C_f_Millimetres = Climate_data.loc[:,'Spring - Milli­metres':'Winter - Milli­metres']\n",
    "C_f_Total_SUN_Hours = Climate_data[['Spring SUN Total Hours',\n",
    "                                              'Summer SUN Total Hours',\n",
    "                                              'Fall SUN Total Hours',\n",
    "                                              'Winter SUN Total Hours']]\n",
    "C_f_SUN_Clear_Days = Climate_data[['Spring SUN Clear Days',\n",
    "                                             'Summer SUN Clear Days', \n",
    "                                             'Fall SUN Clear Days', \n",
    "                                             'Winter SUN Clear Days']]\n",
    "C_f_Humidity_Morning = Climate_data[['Spring Humidity Morn­ing',\n",
    "                                               'Summer Humidity Morn­ing',\n",
    "                                               'Fall Humidity Morn­ing',\n",
    "                                               'Winter Humidity Morn­ing']]\n",
    "C_f_Afternoon = Climate_data[['Spring Humidity After­noon',\n",
    "                                        'Summer Humidity After­noon',\n",
    "                                        'Fall Humidity After­noon',\n",
    "                                        'Winter Humidity After­noon']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_cl_df = [C_f_temp,\n",
    "              C_f_Millimetres,\n",
    "              C_f_Total_SUN_Hours,\n",
    "              C_f_SUN_Clear_Days,\n",
    "              C_f_Humidity_Morning,\n",
    "              C_f_Afternoon]\n",
    "Name_features = ['Avg ° C Temp State_x',\n",
    "                 'Prec Mill State_x',\n",
    "                 'Sun hours State_x',\n",
    "                 'Clear days State_x',\n",
    "                 'Humidity Morning State_x',\n",
    "                 'Humidity Afternoon State_x']\n",
    "State_x_cl_df = pd.DataFrame()\n",
    "index_name = 0\n",
    "for df in List_cl_df:\n",
    "    State_x_cl_df[Name_features[index_name]] = sum_colums_df(df)\n",
    "    index_name += 1\n",
    "State_x_cl_df['State_x'] = Climate_data['State']\n",
    "State_x_cl_df['Part_of_day'] = Climate_data['_2_part_of_day']\n",
    "for i in np.arange(State_x_cl_df.shape[0]):\n",
    "    Part_of_day = State_x_cl_df.loc[i,'Part_of_day']\n",
    "    for col in ['Humidity Morning State_x','Humidity Afternoon State_x']:\n",
    "        if Part_of_day not in col.split(' '):\n",
    "            State_x_cl_df.loc[i, col] = 0\n",
    "State_x_cl_df['Humidity'] = State_x_cl_df['Humidity Morning State_x'] + \\\n",
    "State_x_cl_df['Humidity Afternoon State_x']\n",
    "State_x_cl_df.drop(columns = ['Humidity Morning State_x','Humidity Afternoon State_x','State_x', 'Part_of_day'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg ° C Temp State_x</th>\n",
       "      <th>Prec Mill State_x</th>\n",
       "      <th>Sun hours State_x</th>\n",
       "      <th>Clear days State_x</th>\n",
       "      <th>Humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.9</td>\n",
       "      <td>120.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>27.3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>12.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>-2.1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>-4.8</td>\n",
       "      <td>73.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>7.6</td>\n",
       "      <td>72.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Avg ° C Temp State_x  Prec Mill State_x  Sun hours State_x  Clear days State_x  Humidity\n",
       "0                       25.9              120.0              882.0                22.0      54.0\n",
       "1                        8.6               93.0              716.0                19.0      49.0\n",
       "2                       15.7              100.0              617.0                34.0      53.0\n",
       "3                        7.7               30.0              734.0                42.0      60.0\n",
       "4                       12.1               80.0              565.0                29.0      56.0\n",
       "...                      ...                ...                ...                 ...       ...\n",
       "199995                  27.3               69.0              935.0                41.0      82.0\n",
       "199996                  12.1               80.0              565.0                29.0      56.0\n",
       "199997                  -2.1               56.0              422.0                21.0      66.0\n",
       "199998                  -4.8               73.0              289.0                 8.0      77.0\n",
       "199999                   7.6               72.0              498.0                23.0      88.0\n",
       "\n",
       "[200000 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "State_x_cl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "Climate_data1 = New_xtrain[['Initial Index',\n",
    "                           'Season',\n",
    "                           '_2_part_of_day_land',\n",
    "                           'State_y']]\n",
    "Climate_data1.rename(columns = {'State_y': 'State'}, inplace = True)\n",
    "Climate_data1 = (Climate_data1.merge(Climate_features, on = 'State', how = 'left')).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(Climate_data1.shape[0]):\n",
    "    Season = Climate_data1.loc[i,'Season']\n",
    "    for col in Climate_data1.columns[4:]:\n",
    "        if Season not in col.split(' '):\n",
    "            Climate_data1.loc[i, col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_f_temp1 = Climate_data1.loc[:,'Spring - Avg ° C':'Winter - Avg ° C']\n",
    "C_f_Millimetres1 = Climate_data1.loc[:,'Spring - Milli­metres':'Winter - Milli­metres']\n",
    "C_f_Total_SUN_Hours1 = Climate_data1[['Spring SUN Total Hours',\n",
    "                                              'Summer SUN Total Hours',\n",
    "                                              'Fall SUN Total Hours',\n",
    "                                              'Winter SUN Total Hours']]\n",
    "C_f_SUN_Clear_Days1 = Climate_data1[['Spring SUN Clear Days',\n",
    "                                             'Summer SUN Clear Days', \n",
    "                                             'Fall SUN Clear Days', \n",
    "                                             'Winter SUN Clear Days']]\n",
    "C_f_Humidity_Morning1 = Climate_data1[['Spring Humidity Morn­ing',\n",
    "                                               'Summer Humidity Morn­ing',\n",
    "                                               'Fall Humidity Morn­ing',\n",
    "                                               'Winter Humidity Morn­ing']]\n",
    "C_f_Afternoon1 = Climate_data1[['Spring Humidity After­noon',\n",
    "                                        'Summer Humidity After­noon',\n",
    "                                        'Fall Humidity After­noon',\n",
    "                                        'Winter Humidity After­noon']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_cl_df1 = [C_f_temp1,\n",
    "              C_f_Millimetres1,\n",
    "              C_f_Total_SUN_Hours1,\n",
    "              C_f_SUN_Clear_Days1,\n",
    "              C_f_Humidity_Morning1,\n",
    "              C_f_Afternoon1]\n",
    "Name_features1 = ['Avg ° C Temp State_y',\n",
    "                 'Prec Mill State_y',\n",
    "                 'Sun hours State_y',\n",
    "                 'Clear days State_y',\n",
    "                 'Humidity Morning State_y',\n",
    "                 'Humidity Afternoon State_y']\n",
    "State_y_cl_df = pd.DataFrame()\n",
    "index_name = 0\n",
    "for df in List_cl_df1:\n",
    "    State_y_cl_df[Name_features1[index_name]] = sum_colums_df(df)\n",
    "    index_name += 1\n",
    "State_y_cl_df['State_y'] = Climate_data1['State']\n",
    "State_y_cl_df['Part_of_day'] = Climate_data1['_2_part_of_day_land']\n",
    "for i in np.arange(State_y_cl_df.shape[0]):\n",
    "    Part_of_day = State_y_cl_df.loc[i,'Part_of_day']\n",
    "    for col in ['Humidity Morning State_y','Humidity Afternoon State_y']:\n",
    "        if Part_of_day not in col.split(' '):\n",
    "            State_y_cl_df.loc[i, col] = 0\n",
    "State_y_cl_df['Humidity State_y'] = State_y_cl_df['Humidity Morning State_y'] + \\\n",
    "State_y_cl_df['Humidity Afternoon State_y']\n",
    "State_y_cl_df.drop(columns = ['Humidity Morning State_y','Humidity Afternoon State_y','State_y', 'Part_of_day'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agregate_climate_data = pd.concat([State_x_cl_df, State_y_cl_df], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = pd.concat([New_xtrain,Agregate_climate_data], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_x_train = New_xtrain.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_x_train.drop(columns=['Initial Index',\n",
    "                            'Shift Time',\n",
    "                            '_2_part_of_day',\n",
    "                            '_2_part_of_day_land',\n",
    "                            'Airport_x',\n",
    "                            'IATA_x',\n",
    "                            'Airport_y','IATA_y'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data_types = {'Part of month': 'object',\n",
    "                   'AL_in_Top_fleet_size':'object', \n",
    "                   'AL_in_Top_passengers_carried':'object',\n",
    "                  'Origin airport in top':'object',\n",
    "                  'Dest airport in top':'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.drop(columns=['Initial Index',\n",
    "                            'Shift Time',\n",
    "                            '_2_part_of_day',\n",
    "                            '_2_part_of_day_land',\n",
    "                            'Airport_x',\n",
    "                            'IATA_x',\n",
    "                            'Airport_y','IATA_y'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain['Target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Copy_New_xtrain = New_xtrain.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Copy_New_xtrain.to_csv('Extended all data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>Dep part of day</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Season</th>\n",
       "      <th>Is it holyday</th>\n",
       "      <th>Is it weekend</th>\n",
       "      <th>Part of month</th>\n",
       "      <th>Land time</th>\n",
       "      <th>Land part of day</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Origin_City</th>\n",
       "      <th>State_x</th>\n",
       "      <th>Dest_City</th>\n",
       "      <th>State_y</th>\n",
       "      <th>Origin_Population</th>\n",
       "      <th>Dest_Population</th>\n",
       "      <th>AL_in_Top_fleet_size</th>\n",
       "      <th>AL_in_Top_passengers_carried</th>\n",
       "      <th>Origin airport in top</th>\n",
       "      <th>Dest airport in top</th>\n",
       "      <th>Avg ° C Temp State_x</th>\n",
       "      <th>Prec Mill State_x</th>\n",
       "      <th>Sun hours State_x</th>\n",
       "      <th>Clear days State_x</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Avg ° C Temp State_y</th>\n",
       "      <th>Prec Mill State_y</th>\n",
       "      <th>Sun hours State_y</th>\n",
       "      <th>Clear days State_y</th>\n",
       "      <th>Humidity State_y</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>1934</td>\n",
       "      <td>Evening</td>\n",
       "      <td>732</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Not Holyday</td>\n",
       "      <td>weekend</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1952</td>\n",
       "      <td>Evening</td>\n",
       "      <td>AA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Atlanta Georgia</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Dallas Texas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>1342479.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>120.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1548</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>834</td>\n",
       "      <td>Spring</td>\n",
       "      <td>Not Holyday</td>\n",
       "      <td>not weekend</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1717</td>\n",
       "      <td>Evening</td>\n",
       "      <td>US</td>\n",
       "      <td>PIT</td>\n",
       "      <td>MCO</td>\n",
       "      <td>Pittsburgh Pennsylvania</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Orlando Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>301494.0</td>\n",
       "      <td>281804.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>93.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1422</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>416</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Not Holyday</td>\n",
       "      <td>not weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1506</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>XE</td>\n",
       "      <td>RDU</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Raleigh North Carolina</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Cleveland Ohio</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>465776.0</td>\n",
       "      <td>385252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>100.0</td>\n",
       "      <td>617.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>75.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>1015</td>\n",
       "      <td>Morning</td>\n",
       "      <td>872</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Holyday</td>\n",
       "      <td>weekend</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1248</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>OO</td>\n",
       "      <td>DEN</td>\n",
       "      <td>MEM</td>\n",
       "      <td>Denver Colorado</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Memphis Tennessee</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>704961.0</td>\n",
       "      <td>650878.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>101.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1828</td>\n",
       "      <td>Evening</td>\n",
       "      <td>423</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Not Holyday</td>\n",
       "      <td>weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1913</td>\n",
       "      <td>Evening</td>\n",
       "      <td>WN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>OMA</td>\n",
       "      <td>Chicago Illinois</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Omaha Nebraska</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>2711069.0</td>\n",
       "      <td>476271.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>41.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>852</td>\n",
       "      <td>Morning</td>\n",
       "      <td>187</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Not Holyday</td>\n",
       "      <td>not weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>911</td>\n",
       "      <td>Morning</td>\n",
       "      <td>WN</td>\n",
       "      <td>CRP</td>\n",
       "      <td>HOU</td>\n",
       "      <td>Corpus Christi Texas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Houston Texas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>325568.0</td>\n",
       "      <td>2316750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>1446</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>1515</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Not Holyday</td>\n",
       "      <td>weekend</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1528</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>LAS</td>\n",
       "      <td>Chicago Illinois</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Las Vegas Nevada</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2711069.0</td>\n",
       "      <td>635262.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1509</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>438</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Not Holyday</td>\n",
       "      <td>not weekend</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1555</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>OO</td>\n",
       "      <td>ORD</td>\n",
       "      <td>SGF</td>\n",
       "      <td>Chicago Illinois</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Springfield Missouri</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>2711069.0</td>\n",
       "      <td>167116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>804</td>\n",
       "      <td>Morning</td>\n",
       "      <td>761</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Not Holyday</td>\n",
       "      <td>not weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>925</td>\n",
       "      <td>Morning</td>\n",
       "      <td>DL</td>\n",
       "      <td>LGA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>New York New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>Atlanta Georgia</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>8437478.0</td>\n",
       "      <td>491670.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>73.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>116.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>834</td>\n",
       "      <td>Morning</td>\n",
       "      <td>297</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Not Holyday</td>\n",
       "      <td>not weekend</td>\n",
       "      <td>4.0</td>\n",
       "      <td>905</td>\n",
       "      <td>Morning</td>\n",
       "      <td>OO</td>\n",
       "      <td>MKE</td>\n",
       "      <td>MSP</td>\n",
       "      <td>Milwaukee Wisconsin</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Minneapolis Minnesota</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>593725.0</td>\n",
       "      <td>420925.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>72.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Month DayofMonth DayOfWeek  DepTime Dep part of day  Distance  Season Is it holyday Is it weekend  Part of month  Land time Land part of day UniqueCarrier Origin Dest              Origin_City         State_x              Dest_City    State_y  Origin_Population  Dest_Population  AL_in_Top_fleet_size  AL_in_Top_passengers_carried  Origin airport in top  Dest airport in top  Avg ° C Temp State_x  Prec Mill State_x  Sun hours State_x  Clear days State_x  Humidity  Avg ° C Temp State_y  Prec Mill State_y  Sun hours State_y  Clear days State_y  Humidity State_y  Target\n",
       "0          8         21         7     1934        Evening        732  Summer   Not Holyday       weekend            3.0       1952         Evening             AA    ATL  DFW          Atlanta Georgia         Georgia           Dallas Texas      Texas           491670.0        1342479.0                     0                             0                      1                    1                  25.9              120.0              882.0                22.0      54.0                  27.3               69.0              935.0                41.0              44.0     0.0\n",
       "1          4         20         3     1548       Afternoon       834  Spring   Not Holyday   not weekend            3.0       1717         Evening             US    PIT  MCO  Pittsburgh Pennsylvania    Pennsylvania        Orlando Florida    Florida           301494.0         281804.0                     0                             0                      1                    1                   8.6               93.0              716.0                19.0      49.0                  21.1               92.0              881.0                33.0              52.0     0.0\n",
       "2          9          2         5     1422       Afternoon       416    Fall   Not Holyday   not weekend            1.0       1506        Afternoon            XE    RDU  CLE   Raleigh North Carolina  North Carolina         Cleveland Ohio       Ohio           465776.0         385252.0                     0                             0                      1                    1                  15.7              100.0              617.0                34.0      53.0                  11.6               75.0              499.0                24.0              56.0     0.0\n",
       "3         11         25         6     1015         Morning       872    Fall       Holyday       weekend            4.0       1248        Afternoon            OO    DEN  MEM          Denver Colorado        Colorado      Memphis Tennessee  Tennessee           704961.0         650878.0                     0                             0                      1                    0                   7.7               30.0              734.0                42.0      60.0                  14.8              101.0              591.0                33.0              52.0     0.0\n",
       "4         10          7         6     1828        Evening        423    Fall   Not Holyday       weekend            1.0       1913         Evening             WN    MDW  OMA         Chicago Illinois        Illinois         Omaha Nebraska   Nebraska          2711069.0         476271.0                     1                             1                      1                    0                  12.1               80.0              565.0                29.0      56.0                   9.7               41.0              610.0                34.0              52.0     1.0\n",
       "...      ...        ...       ...      ...             ...       ...     ...           ...           ...            ...        ...              ...           ...    ...  ...                      ...             ...                    ...        ...                ...              ...                   ...                           ...                    ...                  ...                   ...                ...                ...                 ...       ...                   ...                ...                ...                 ...               ...     ...\n",
       "199995     6          5         2      852         Morning       187  Summer   Not Holyday   not weekend            1.0        911          Morning            WN    CRP  HOU     Corpus Christi Texas           Texas          Houston Texas      Texas           325568.0        2316750.0                     1                             1                      0                    1                  27.3               69.0              935.0                41.0      82.0                  27.3               69.0              935.0                41.0              82.0     NaN\n",
       "199996    11         24         6     1446       Afternoon      1515    Fall   Not Holyday       weekend            4.0       1528        Afternoon            UA    ORD  LAS         Chicago Illinois        Illinois       Las Vegas Nevada     Nevada          2711069.0         635262.0                     0                             0                      1                    1                  12.1               80.0              565.0                29.0      56.0                  10.1               19.0              851.0                46.0              30.0     NaN\n",
       "199997     1         30         2     1509       Afternoon       438  Winter   Not Holyday   not weekend            4.0       1555        Afternoon            OO    ORD  SGF         Chicago Illinois        Illinois   Springfield Missouri   Missouri          2711069.0         167116.0                     0                             0                      1                    0                  -2.1               56.0              422.0                21.0      66.0                   0.2               58.0              471.0                24.0              56.0     NaN\n",
       "199998     1          5         5      804         Morning       761  Winter   Not Holyday   not weekend            1.0        925          Morning            DL    LGA  ATL        New York New York        New York        Atlanta Georgia    Georgia          8437478.0         491670.0                     1                             1                      1                    1                  -4.8               73.0              289.0                 8.0      77.0                   8.8              116.0              554.0                25.0              81.0     NaN\n",
       "199999    10         29         1      834         Morning       297    Fall   Not Holyday   not weekend            4.0        905          Morning            OO    MKE  MSP      Milwaukee Wisconsin       Wisconsin  Minneapolis Minnesota  Minnesota           593725.0         420925.0                     0                             0                      0                    1                   7.6               72.0              498.0                23.0      88.0                   6.4               57.0              527.0                25.0              82.0     NaN\n",
       "\n",
       "[200000 rows x 36 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Copy_New_xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = pd.read_csv('Data for comp/Extended all data acre climate.csv')\n",
    "Air_Port_data = pd.read_csv('Data for comp/Fixes Airpord data.csv')\n",
    "New_xtrain.drop(columns = ['Acre_x','Acre_y'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Air_Port_data = Air_Port_data[['IATA','Acre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = New_xtrain.merge(Air_Port_data, left_on='Origin', right_on='IATA')\n",
    "New_xtrain = New_xtrain.merge(Air_Port_data, left_on='Dest', right_on='IATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Air_Port_data.loc[140, 'Acre'] = 650\n",
    "Air_Port_data.loc[218, 'Acre'] = 2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.sort_values(by = 'Unnamed: 0', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.drop(columns = ['IATA_x','IATA_y'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.index = np.arange(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "States_Population = pd.read_excel('Data for comp/States_population .xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = New_xtrain['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain['Internal flight'] =(New_xtrain['State_x'] + ','+ New_xtrain['State_y']).apply(lambda x: int(x.split(',')[0] == x.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.drop(columns=['Target'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([x_train, x_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Flight'] = all_data['Origin'] +'-'+ all_data['Dest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['Carrier-Flight'] = all_data['Flight'] + '-'+ all_data['UniqueCarrier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flight_data = all_data[['UniqueCarrier', 'Flight', 'Carrier-Flight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict_UniqueCarrier = dict(Flight_data['UniqueCarrier'].value_counts(normalize = True))\n",
    "Dict_Flight = dict(Flight_data['Flight'].value_counts(normalize = True))\n",
    "Dict_Carrier_Flight = dict(Flight_data['Carrier-Flight'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain['Share UniqueCarrier'] = New_xtrain['UniqueCarrier'].map(Dict_UniqueCarrier)\n",
    "New_xtrain['Share Flight'] = (New_xtrain['Origin'] +'-'+ New_xtrain['Dest']).map(Dict_Flight)\n",
    "New_xtrain['Share Carrier-Flight'] = ((New_xtrain['Origin'] +'-'+ New_xtrain['Dest'])+'-'+New_xtrain['UniqueCarrier']).map(Dict_Carrier_Flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = New_xtrain.merge(States_Population, left_on='State_x', right_on='State')\n",
    "New_xtrain.drop(columns = ['State'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.rename(columns={'July 2019 Estimate':'Population State_x'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = New_xtrain.merge(States_Population, left_on='State_y', right_on='State')\n",
    "New_xtrain.drop(columns = ['State'], inplace = True)\n",
    "New_xtrain.rename(columns={'July 2019 Estimate':'Population State_y'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.index = np.arange(200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.sort_values(by = 'Unnamed: 0', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.drop(columns=['Unnamed: 0','Unnamed: 0.1'],inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain = pd.concat([New_xtrain,Target ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_xtrain.to_csv('Final all data flight delays.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
