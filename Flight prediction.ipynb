{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max.columns', 100)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from calendar import monthrange \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.manifold import TSNE\n",
    "pd.set_option('display.width', 1000) \n",
    "pd.set_option ('display.max_columns' , 1000)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_log_data (x_data, elim_columns = [], sum_num_to_data = 0):\n",
    "    data = x_data.copy()\n",
    "    columns = data.columns\n",
    "    for col in columns:\n",
    "        if col in elim_columns:\n",
    "            continue\n",
    "        else:\n",
    "            if data[col].dtype == 'float64':\n",
    "                list_index = list(data[data[col] != 0][col].index)\n",
    "                data.loc[list_index, col] = data.loc[list_index, col].apply(np.log10)\n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drow_data (x_data, y_data):\n",
    "    tsne = TSNE(random_state=17)\n",
    "\n",
    "    X_tsne = tsne.fit_transform(x_data)\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_data, \n",
    "                edgecolor='none', alpha=0.7, s=40,\n",
    "                cmap=plt.cm.get_cmap('nipy_spectral', 2))\n",
    "    plt.colorbar()\n",
    "    plt.title('MNIST. t-SNE projection');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_enc1(train_df, y_train, valid_df, skf):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    glob_mean = y_train.mean()\n",
    "    train_df = pd.concat([train_df, pd.Series(y_train, name='y')], axis=1)\n",
    "    new_train_df = train_df.copy()\n",
    "    \n",
    "    cat_features = train_df.columns[train_df.dtypes == 'object'].tolist()    \n",
    "\n",
    "    for col in cat_features:\n",
    "        new_train_df[col + '_mean_target'] = np.nan\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(train_df, y_train):\n",
    "        train_df_cv, valid_df_cv = train_df.iloc[train_idx, :], train_df.iloc[valid_idx, :]\n",
    "\n",
    "        for col in cat_features:\n",
    "            \n",
    "            means = valid_df_cv[col].map(train_df_cv.groupby(col)['y'].mean())\n",
    "            valid_df_cv[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "            \n",
    "        new_train_df.iloc[valid_idx] = valid_df_cv\n",
    "    \n",
    "    for col in cat_features:\n",
    "        means = valid_df[col].map(train_df.groupby(col)['y'].mean())\n",
    "        valid_df[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "    \n",
    "    return new_train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_enc_train(train_df, y_train, skf):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    glob_mean = y_train.mean()\n",
    "    train_df = pd.concat([train_df, pd.Series(y_train, name='y')], axis=1)\n",
    "    new_train_df = train_df.copy()\n",
    "    \n",
    "    cat_features = train_df.columns[train_df.dtypes == 'object'].tolist()    \n",
    "\n",
    "    for col in cat_features:\n",
    "        new_train_df[col + '_mean_target'] = np.nan\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(train_df, y_train):\n",
    "        train_df_cv, valid_df_cv = train_df.iloc[train_idx, :], train_df.iloc[valid_idx, :]\n",
    "\n",
    "        for col in cat_features:\n",
    "            \n",
    "            means = valid_df_cv[col].map(train_df_cv.groupby(col)['y'].mean())\n",
    "            valid_df_cv[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "            \n",
    "        new_train_df.iloc[valid_idx] = valid_df_cv\n",
    "    new_train_df.drop(cat_features + [\"y\"], axis=1, inplace=True)\n",
    "    return new_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_bad_features (Model, x_data, y_data, n_splits_on_CV):\n",
    "    cv = StratifiedKFold(n_splits= n_splits_on_CV, random_state= 17)\n",
    "    features = x_data.columns\n",
    "    differences = []\n",
    "    percent_dif = []\n",
    "    std = []\n",
    "    percent_std = []\n",
    "    cv_before_drop_feature = cross_val_score(Model, x_data, \n",
    "                                                 y_data, scoring='roc_auc', n_jobs= -1, cv = cv)\n",
    "    for feature in features:\n",
    "        cut_x_data = x_data.drop(columns=[feature])\n",
    "        cv_after_drop_feature = cross_val_score(Model, cut_x_data, \n",
    "                                                 y_data, scoring='roc_auc', n_jobs= -1, cv = cv)\n",
    "        difference = cv_after_drop_feature.mean() - cv_before_drop_feature.mean()\n",
    "        percent_df = (cv_after_drop_feature.mean()/cv_before_drop_feature.mean() - 1) * 100\n",
    "        std_dif = cv_after_drop_feature.std() - cv_before_drop_feature.std() \n",
    "        percent_std_ = (cv_after_drop_feature.std()/cv_before_drop_feature.std() - 1) * 100\n",
    "        differences.append(difference)\n",
    "        percent_dif.append(percent_df)\n",
    "        std.append(std_dif)\n",
    "        percent_std.append(percent_std_)\n",
    "    df = pd.DataFrame({'Feature': pd.Series(features), 'CV_Diff': pd.Series(differences), \n",
    "                       'CV_Diff %': pd.Series(percent_dif), \n",
    "                       'Diff Std of CV': pd.Series(std),'Diff Std of CV %': pd.Series(percent_std)})\n",
    "    sorted_df = df.sort_values(by = 'CV_Diff', ascending= True)\n",
    "    return sorted_df.set_index(np.arange(1, len(features) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_fetures (Model , x_data, y_data, n_splits_on_CV):\n",
    "    cv = StratifiedKFold(n_splits= n_splits_on_CV, random_state= 17)\n",
    "    features = x_data.columns\n",
    "    for i in range (len(features)):\n",
    "        impact_of_all_features = determine_bad_features(Model , x_data, y_data , n_splits_on_CV)\n",
    "        if impact_of_all_features.loc[impact_of_all_features.shape[0] - 1, 'CV_Diff'] > 0:\n",
    "            the_worst_feature = impact_of_all_features.loc[impact_of_all_features.shape[0] - 1, 'Feature']\n",
    "            x_data = x_data.drop(columns = [the_worst_feature])\n",
    "        else:\n",
    "            break\n",
    "    Excepted_features = list(set(features) - set(x_data.columns))\n",
    "    return x_data.columns , ('Excepted_features', Excepted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(table):\n",
    "    for col in table.columns:\n",
    "        if table[col].dtype == 'int64' or table[col].dtype == 'float64':\n",
    "            table[col] = table[col].fillna(table[col].mean())\n",
    "    return table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencoding_data (data, encoding_more = True, limit =  4):\n",
    "    cat_features = []\n",
    "    float_int_features = []\n",
    "    if encoding_more:\n",
    "        for col in data.columns:\n",
    "            if data[col].dtype == 'object'and (2 < data[col].nunique() <= limit):\n",
    "                cat_features.append(col)\n",
    "            elif data[col].dtype == 'object'and data[col].nunique() == 2:\n",
    "                dict_col = dict(data[col].value_counts())\n",
    "                mark = 0\n",
    "                for key in dict_col:\n",
    "                    dict_col[key] = mark\n",
    "                    mark += 1\n",
    "                data[col] = data[col].map(dict_col)\n",
    "                float_int_features.append(col)\n",
    "            else:\n",
    "                float_int_features.append(col)\n",
    "        one_hot_data = pd.get_dummies(data[cat_features])\n",
    "        return pd.concat([data[float_int_features],one_hot_data], axis = 1)\n",
    "    else:\n",
    "        for col in data.columns:\n",
    "            if data[col].dtype == 'object'and data[col].nunique() == 2:\n",
    "                dict_col = dict(data[col].value_counts())\n",
    "                mark = 0\n",
    "                for key in dict_col:\n",
    "                    dict_col[key] = mark\n",
    "                    mark += 1\n",
    "                data[col] = data[col].map(dict_col)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comply_good_df (Model, x_data , y_data, cv, show_elim_features = False):\n",
    "    Inner_skf = StratifiedKFold(n_splits= cv, random_state= 17)\n",
    "    features = x_data.columns.tolist()\n",
    "    complied_df = pd.DataFrame()\n",
    "    best_temp_score = 0\n",
    "    best_gen_score = 0\n",
    "    for iter in range(x_data.shape[1]):\n",
    "        for feature in features:\n",
    "            temp_df = complied_df.copy()\n",
    "            temp_df[feature] = x_data[feature]\n",
    "            feature_scores = cross_val_score(Model, temp_df, y_data, cv = Inner_skf,\n",
    "                                             scoring= 'roc_auc', n_jobs= -1)\n",
    "            mean_score_with_feature =  feature_scores.mean()\n",
    "            if mean_score_with_feature > best_temp_score:\n",
    "                best_temp_score = mean_score_with_feature\n",
    "                best_feature = feature\n",
    "        if best_temp_score > best_gen_score:\n",
    "            complied_df[best_feature] = x_data[best_feature]\n",
    "            features.remove(best_feature)\n",
    "            best_gen_score = best_temp_score\n",
    "        else:\n",
    "            break\n",
    "    elim_features = list(set(x_data.columns) - set(complied_df.columns))\n",
    "    if show_elim_features:\n",
    "        return complied_df, elim_features\n",
    "    else:\n",
    "        return complied_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot_all_num_features_by_class (x_data, y_data, figsize = (20, 30)):\n",
    "    inner_df = pd.concat([x_data, y_data], axis = 1)\n",
    "    num_features = x_data.shape[1]\n",
    "    ncols = 3\n",
    "    nrows = (num_features // ncols) + 1\n",
    "    fig, axes = plt.subplots(nrows= nrows, ncols=3, figsize=(20, 30))\n",
    "    for idx, feat in enumerate(x_data.columns):\n",
    "        ax = axes[int(idx/3) , idx%3]\n",
    "        sns.boxplot(x = 'Target', y = feat, data = inner_df, ax = ax)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel(feat)\n",
    "    fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_features (x_data, y_data, deep = 3,add_features = False, use_each_column = False, deep_each_col = 1):\n",
    "    List_features = x_data.columns.tolist()\n",
    "    Tree_features = pd.DataFrame()\n",
    "    if use_each_column:\n",
    "        Tree = DecisionTreeClassifier(max_depth= deep_each_col, random_state= 17)\n",
    "        for feature in List_features:\n",
    "            Tree.fit(np.array(x_data[feature]).reshape(-1, 1), y_data)\n",
    "            Threshold = Tree.tree_.threshold.tolist()\n",
    "            for Thresh in Threshold:\n",
    "                if Thresh == -2:\n",
    "                    continue\n",
    "                else:\n",
    "                    if add_features:\n",
    "                        x_data[feature+ ' '+ '<=' + ' '+str(Thresh)] = x_data[feature].apply(lambda x:int(x <= Thresh))\n",
    "                    else:\n",
    "                        Tree_features[feature+ ' '+ '<=' + ' '+str(Thresh)] = x_data[feature].apply(lambda x:int(x <= Thresh))\n",
    "        if add_features:\n",
    "            return x_data\n",
    "        else:\n",
    "            return  Tree_features\n",
    "    else:\n",
    "        Tree = DecisionTreeClassifier(max_depth= deep, random_state= 17)\n",
    "        Tree.fit(x_data, y_data)\n",
    "        Features = Tree.tree_.feature.tolist()\n",
    "        Threshold = Tree.tree_.threshold.tolist()\n",
    "        for Thresh, Feature in [*zip(Threshold, Features)]:\n",
    "            if Thresh == -2 and Feature ==  -2:\n",
    "                continue\n",
    "            else:\n",
    "                if add_features:\n",
    "                    Col = List_features[Feature]\n",
    "                    x_data[Col+ ' '+ '<=' + ' '+str(Thresh)] = x_data[Col].apply(lambda x:int(x <= Thresh))\n",
    "                else:\n",
    "                    Col = List_features[Feature]\n",
    "                    Tree_features[Col+ ' '+ '<=' + ' '+str(Thresh)] = x_data[Col].apply(lambda x:int(x <= Thresh))\n",
    "        if add_features:\n",
    "            return x_data\n",
    "        else:\n",
    "            return  Tree_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model_output (Model, x_data, y_data, num_cross_val = 5, add_feature = True):\n",
    "    x_data = x_data.copy()\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    Inner_SKF = StratifiedKFold(n_splits=  num_cross_val, shuffle= True, random_state= 17)\n",
    "    Model_outputs = pd.Series(np.zeros(x_data.shape[0]))\n",
    "    ROC_AUC = []\n",
    "    for train_df_id , apply_df_id in Inner_SKF.split(x_data, y_data):\n",
    "        train_df_x = x_data.iloc[train_df_id, :]\n",
    "        train_df_Y = y_data[train_df_id]\n",
    "        apply_df = x_data.iloc[apply_df_id, :]\n",
    "        Model.fit(train_df_x, train_df_Y)\n",
    "        out_put = pd.Series(Model.predict_proba(apply_df)[:, 1])\n",
    "        Model_outputs[apply_df_id] = out_put\n",
    "        roc_auc = roc_auc_score(y_data[apply_df_id], out_put)\n",
    "        ROC_AUC.append(roc_auc)\n",
    "    if add_feature:\n",
    "        x_data[str(Model).split('(')[0]] = Model_outputs\n",
    "        return x_data\n",
    "    else:\n",
    "        return Model_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_df_model_feature (Model, x_data, y_data, num_cross_val = 5, replace_output = True):\n",
    "    x_data = x_data.copy()\n",
    "    inner_skf = StratifiedKFold(n_splits= num_cross_val, shuffle= True, random_state= 17)\n",
    "    mean_score = 0\n",
    "    previous_mean_score = 0\n",
    "    iteration = 0\n",
    "    while mean_score >= previous_mean_score:\n",
    "        if replace_output:\n",
    "            Out_put = add_model_output(Model,\n",
    "                                       x_data, \n",
    "                                       y_data, \n",
    "                                       num_cross_val = num_cross_val,\n",
    "                                       add_feature = False)\n",
    "            previous_df = x_data.copy()\n",
    "            x_data[str(Model).split('(')[0]] = Out_put\n",
    "            inner_scores = cross_val_score(Model, \n",
    "                                           x_data, y_data, cv = inner_skf, scoring='roc_auc')\n",
    "            previous_mean_score = mean_score\n",
    "            mean_score = inner_scores.mean()\n",
    "        else:\n",
    "            Out_put = add_model_output(Model,\n",
    "                                       x_data, \n",
    "                                       y_data, \n",
    "                                       num_cross_val = num_cross_val,\n",
    "                                       add_feature = False)\n",
    "            previous_df = x_data.copy()\n",
    "            x_data[str(Model).split('(')[0] + str(iteration)] = Out_put\n",
    "            inner_scores = cross_val_score(Model, x_data, y_data,\n",
    "                                           cv = inner_skf, scoring = 'roc_auc')\n",
    "            previous_mean_score = mean_score\n",
    "            mean_score = inner_scores.mean()\n",
    "            iteration += 1\n",
    "    return previous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_features (x_data, y_data, deep = 3,add_features = False, use_each_column = False, deep_each_col = 1):\n",
    "    x_data = x_data.copy()\n",
    "    List_features = x_data.columns.tolist()\n",
    "    Tree_features = pd.DataFrame()\n",
    "    if use_each_column:\n",
    "        Tree = DecisionTreeRegressor(max_depth= deep_each_col, random_state= 17)\n",
    "        for feature in ['Avg Â° C', 'Millimetres','SUN Total Hours', 'SUN Clear Days', 'Humidity State']:\n",
    "            Tree.fit(np.array(x_data[feature]).reshape(-1, 1), y_data)\n",
    "            Threshold = Tree.tree_.threshold.tolist()\n",
    "            for Thresh in Threshold:\n",
    "                if Thresh == -2:\n",
    "                    continue\n",
    "                else:\n",
    "                    if add_features:\n",
    "                        x_data[feature+ ' '+ '<=' + ' '+str(Thresh)] = x_data[feature].apply(lambda x:int(x <= Thresh))\n",
    "                    else:\n",
    "                        Tree_features[feature+ ' '+ '<=' + ' '+str(Thresh)] = x_data[feature].apply(lambda x:int(x <= Thresh))\n",
    "        if add_features:\n",
    "            return x_data\n",
    "        else:\n",
    "            return  Tree_features\n",
    "    else:\n",
    "        Tree = DecisionTreeRegressor(max_depth= deep, random_state= 17)\n",
    "        Tree.fit(x_data, y_data)\n",
    "        Features = Tree.tree_.feature.tolist()\n",
    "        Threshold = Tree.tree_.threshold.tolist()\n",
    "        for Thresh, Feature in [*zip(Threshold, Features)]:\n",
    "            if Thresh == -2 and Feature ==  -2:\n",
    "                continue\n",
    "            else:\n",
    "                if add_features:\n",
    "                    Col = List_features[Feature]\n",
    "                    x_data[Col+ ' '+ '<=' + ' '+str(Thresh)] = x_data[Col].apply(lambda x:int(x <= Thresh))\n",
    "                else:\n",
    "                    Col = List_features[Feature]\n",
    "                    Tree_features[Col+ ' '+ '<=' + ' '+str(Thresh)] = x_data[Col].apply(lambda x:int(x <= Thresh))\n",
    "        if add_features:\n",
    "            return x_data\n",
    "        else:\n",
    "            return  Tree_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_features_on_cv (Model, x_data, y_data, scoring = 'roc_auc', num_cv = 5, \n",
    "                         shuffle = True, deep_tree = 1, use_each_column = False, deep_each_col = 1):\n",
    "    x_data = x_data.copy()\n",
    "    Inner_SKF = StratifiedKFold(random_state= 17, n_splits=num_cv, shuffle = shuffle)\n",
    "    scores = []\n",
    "    for train_df_id, apply_df_id in Inner_SKF.split(x_data, y_data):\n",
    "        train_df_x = x_data.iloc[train_df_id, :]\n",
    "        train_df_y = y_data[train_df_id]\n",
    "        apply_df_x = x_data.iloc[apply_df_id, :]\n",
    "        apply_df_y = y_data[apply_df_id]\n",
    "        train_df_x_tree = tree_features(train_df_x, \n",
    "                                        train_df_y,\n",
    "                                        use_each_column= use_each_column, \n",
    "                                        deep_each_col= deep_each_col,\n",
    "                                        deep= deep_tree,\n",
    "                                        add_features=True)\n",
    "        Model.fit(train_df_x_tree, train_df_y)\n",
    "        Features = (tree_features(train_df_x, \n",
    "                                        train_df_y,\n",
    "                                        use_each_column= use_each_column, \n",
    "                                        deep = deep_tree,\n",
    "                                        deep_each_col= deep_each_col,\n",
    "                                        add_features = False)).columns\n",
    "        apply_df_x_treee = apply_tree_features_to_test(Features, apply_df_x)\n",
    "        if scoring == 'r2':\n",
    "            Y_pred = Model.predict(apply_df_x_treee)\n",
    "            r_2 = r2_score(Y_pred, apply_df_y)\n",
    "            scores.append(r_2)\n",
    "        elif scoring == 'roc_auc':\n",
    "            Y_pred = Model.predict_proba(apply_df_x_treee)\n",
    "            roc_auc = roc_auc_score(Y_pred, apply_df_y)\n",
    "            scores.append(roc_auc)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_out_put_on_cv (Model, x_data, y_data, num_cv = 5, num_cv_model = 5,  shuffle = True, scoring = 'roc_auc'):\n",
    "    x_data = x_data.copy()\n",
    "    Inner_SKF = StratifiedKFold(random_state= 17, n_splits=num_cv, shuffle = shuffle)\n",
    "    warnings.filterwarnings('ignore')\n",
    "    scores = []\n",
    "    mean_inner_scores = []\n",
    "    for train_id, test_id in Inner_SKF.split(x_data, y_data):\n",
    "        x_train = x_data.iloc[train_id,:]\n",
    "        x_train.index = np.arange(x_train.shape[0])\n",
    "        y_train = y_data[train_id]\n",
    "        y_train.index = np.arange(x_train.shape[0])\n",
    "        x_test = x_data.iloc[test_id,:]\n",
    "        x_test.index = np.arange(x_test.shape[0])\n",
    "        y_test = y_data[test_id]\n",
    "        y_test.index = np.arange(x_test.shape[0])\n",
    "        x_train_model_out_put = add_model_output(Model, x_train,  y_train, num_cross_val= num_cv_model, add_feature= True)\n",
    "        if scoring == 'roc_auc':\n",
    "            Inner_scores = cross_val_score(Model,\n",
    "                                           x_train_model_out_put,\n",
    "                                           y_train,\n",
    "                                           n_jobs= -1, \n",
    "                                           cv= Inner_SKF, \n",
    "                                           scoring='roc_auc')\n",
    "            Mean_cv = Inner_scores.mean()\n",
    "            mean_inner_scores.append(Mean_cv)\n",
    "            Model.fit(x_train ,y_train)\n",
    "            x_test['Model_output'] = Model.predict_proba(x_test)\n",
    "            Model.fit(x_train_model_out_put, y_train)\n",
    "            Predicted_val = Model.predict_proba(x_test)\n",
    "            roc_auc = roc_auc_score(Predicted_val, y_test)\n",
    "            scores.append(roc_auc)\n",
    "        elif scoring == 'r2':\n",
    "            Inner_scores = cross_val_score(Model,\n",
    "                                           x_train_model_out_put,\n",
    "                                           y_train,\n",
    "                                           n_jobs= -1, \n",
    "                                           cv= Inner_SKF, \n",
    "                                           scoring='r2')\n",
    "            Mean_cv = Inner_scores.mean()\n",
    "            mean_inner_scores.append(Mean_cv)\n",
    "            Model.fit(x_train ,y_train)\n",
    "            x_test['Model_output'] = Model.predict(x_test)\n",
    "            Model.fit(x_train_model_out_put, y_train)\n",
    "            Predicted_val = Model.predict(x_test)\n",
    "            r_2 = r2_score(Predicted_val, y_test)\n",
    "            scores.append(r_2)\n",
    "    return np.array(scores) , np.array(mean_inner_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_fetures (Model, x_data, y_data, thresh, power_ , num_cv = 5, add_features = False):\n",
    "    Inner_SKF = StratifiedKFold(n_splits=num_cv, random_state= 17)\n",
    "    x_data = x_data.copy()\n",
    "    init_x_data = x_data.copy()\n",
    "    int_float_col = []\n",
    "    base_score = (cross_val_score(Model, init_x_data, y_data, n_jobs= -1, cv = Inner_SKF, scoring = 'r2')).mean()\n",
    "    for col in x_data.columns:\n",
    "        unique_values = len(set(x_data[col]))\n",
    "        if x_data[col].dtype == 'float64' or x_data[col].dtype == 'int64' and unique_values > thresh:\n",
    "            int_float_col.append(col)\n",
    "    for power in np.arange(2, power_ + 1):\n",
    "        x_data_pow = init_x_data[int_float_col] ** power\n",
    "        x_data_pow.columns = [*map(lambda x: x + ' ' +'in'+' '+str(power)+' '+'power' , x_data_pow.columns)]\n",
    "        power_features = x_data_pow.columns.tolist()\n",
    "        for i in np.arange(len(int_float_col)):\n",
    "            max_score = 0\n",
    "            for col in power_features:\n",
    "                Inner_x_data = x_data.copy()\n",
    "                Inner_x_data[col] = x_data_pow[col]\n",
    "                score = (cross_val_score(Model, Inner_x_data,\n",
    "                                         y_data, n_jobs= -1, cv = Inner_SKF, scoring = 'roc_auc')).mean()\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    best_feature = col\n",
    "            if max_score > base_score:\n",
    "                base_score = max_score\n",
    "                power_features.remove(best_feature)\n",
    "                x_data[best_feature] = x_data_pow[best_feature]\n",
    "            else:\n",
    "                break\n",
    "    if add_features:\n",
    "        return x_data\n",
    "    else:\n",
    "        add_features = list(set(x_data.columns) - set(init_x_data.columns))\n",
    "        return x_data.loc[:,add_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult_fetures (Model, x_data, y_data, thresh, num_cv = 5, max_features = False, mult_comb = 5, add_features = False):\n",
    "    def accum_prodict_df (df):\n",
    "        prodict_df = pd.Series(np.ones(df.shape[0]))\n",
    "        for col in df.columns:\n",
    "            prodict_df *= df[col]\n",
    "        return prodict_df\n",
    "    Inner_SKF = StratifiedKFold(n_splits=num_cv, random_state= 17)\n",
    "    x_data = x_data.copy()\n",
    "    init_x_data = x_data.copy()\n",
    "    int_float_col = []\n",
    "    base_score = (cross_val_score(Model, init_x_data, y_data, n_jobs= -1, cv = Inner_SKF, scoring = 'r2')).mean()\n",
    "    for col in x_data.columns:\n",
    "        unique_values = len(set(x_data[col]))\n",
    "        if x_data[col].dtype == 'float64' or x_data[col].dtype == 'int64' and unique_values > thresh:\n",
    "            int_float_col.append(col)\n",
    "    if max_features:\n",
    "        mult_comb = len(int_float_col)\n",
    "    for num_comb in np.arange(2, mult_comb + 1):\n",
    "        feature_combinations = [*itertools.combinations(int_float_col, num_comb)]\n",
    "        x_data_comb = pd.DataFrame()\n",
    "        for comb in feature_combinations:\n",
    "            df_feature_mult = init_x_data.loc[:, list(comb)]\n",
    "            df__multiplied = accum_prodict_df(df_feature_mult)\n",
    "            x_data_comb['PRODUCT OF'+ ' ('+', '.join(df_feature_mult.columns)+')'] = df__multiplied\n",
    "        comb_features = x_data_comb.columns.tolist()\n",
    "        for i in np.arange(len(int_float_col)):\n",
    "            max_score = 0\n",
    "            for col in comb_features:\n",
    "                Inner_x_data = x_data.copy()\n",
    "                Inner_x_data[col] = x_data_comb[col]\n",
    "                score = (cross_val_score(Model, Inner_x_data,\n",
    "                                         y_data, n_jobs= -1, cv = Inner_SKF, scoring = 'roc_auc')).mean()\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    best_feature = col\n",
    "            if max_score > base_score:\n",
    "                base_score = max_score\n",
    "                comb_features.remove(best_feature)\n",
    "                x_data[best_feature] = x_data_comb[best_feature]\n",
    "            else:\n",
    "                break\n",
    "    if add_features:\n",
    "        return x_data\n",
    "    else:\n",
    "        add_features = list(set(x_data.columns) - set(init_x_data.columns))\n",
    "        return x_data.loc[:,add_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_features_by_Lasso (x_data, y_data):\n",
    "    Lasso_reg = Lasso()\n",
    "    Lasso_reg.fit(x_data, y_data)\n",
    "    num_col = []\n",
    "    for i, b in enumerate(Lasso_reg.coef_):\n",
    "        if b != 0:\n",
    "            num_col.append(i)\n",
    "    Lasso_df = x_data.iloc[:,num_col]\n",
    "    return Lasso_df\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
